\section{November 7, 2022}

\subsection{Bilinear Forms}

\begin{definition}
\deflabel

Let $V$ vector space over $F$. A \ac{bilinear form} on $V$ is a function $V\times V\rightarrow F$, $(x,y)\mapsto \gen{x,y}$ such that
\begin{itemize}
    \item $\gen{\lambda x,y} = \gen{x, \lambda y} = \lambda \gen{x,y}$
    \item $\gen{x_1 + x_2, y} = \gen{x_1,y} + \gen{x_2, y}$
    \item $\gen{x_1, y_1 + y_2} = \gen{x, y_1} + \gen{x, y_2}$
\end{itemize}
for all $\lambda\in F$, $x_1, x_2, y_1, y_2, x, y\in V$. 
\end{definition}

The first condition takes care of scalar multiplication, while the second and third conditions imply that our function is linear in both the first and second variable, hence ``bilinear".

\begin{theorem}
\proplabel

Let $V = F^n$. For any $A\in F^{n\times n}$, $\gen{x,y} = x^t Ay$ is a bilinear form. Moreover, all bilinear forms on $F^n$ are of this form. 
\end{theorem}

\begin{proof}
It is easy to verify that functions of this form are bilinear forms, so let's prove the other direction.

Consider the standard basis $e_1, \hdots, e_n$, where 

\[x = \begin{pmatrix}x_1\\ \vdots \\x_n
\end{pmatrix} = \sum_i x_ie_i \quad\text{ and }\quad y = \begin{pmatrix}y_1\\ \vdots \\y_n \end{pmatrix} = \sum_i y_ie_i.\] 

Then our bilinear form
\begin{align*}
    \lgen{\sum_i x_ie_i, \sum_j y_je_j} &= \sum_i x_i \lgen{e_i, \sum_j y_je_j} \\
    &= \sum_{i,j}x_iy_j \lgen{e_i, e_j} \\
    &= x^tAy,
\end{align*}
where $A$ is uniquely defined by $A_{ij} = \gen{e_i, e_j}$.

\end{proof}

What happens when we change our basis? Let 
\[B = \begin{pmatrix}
    \vert & & \vert \\
    b_1   & \hdots & b_n   \\
    \vert & & \vert
\end{pmatrix}\]
be the basis matrix transforming $\{e_1, \hdots, e_n\}$ to $\{b_1, \hdots, b_n\}$, i.e., $Be_i = b_i$. Then we have 
\[\gen{Bx, By} = (Bx)^tABy = x^t(B^tAB)y,\] 
so the effect of changing our basis was effectively $A\mapsto B^tAB$. 

Note the similarities between binary forms and linear operators. Both can be represented by matrices, but the basis transformation for a linear operator is conjugation, while the basis transformation for a binary form is $A\mapsto B^tAB$. \textbf{These are very different!}

\begin{definition}
\deflabel

A bilinear form $\gen{\cdot, \cdot}$ is \ac{symmetric} if $\gen{x,y} = \gen{y,x}\quad \forall x,y\in V$. 
\end{definition}

Since $\gen{x,y} \in F$, $\gen{x,y}^t = \gen{x,y}$, so we can say that
$x^tAy = (x^tAy)^t = y^tA^tx$. In other words, a binary form is symmetric if and only if $A = A^t$. This property of symmetry is preserved under the change of basis $A\mapsto B^tAB$, as we should expect.

\subsection{Inner Products and Hermitian forms}

Now let's look at the real numbers, $F = \RR$. Over this field, inequalities are well-defined.
\begin{definition}
\deflabel

A bilinear form $\gen{\cdot,\cdot}$ is \ac{positive semidefinite} if $\gen{x,x} \geq 0\quad \forall x\in V$. Additionally, we say it is \ac{positive definite} if also $\gen{x,x}=0\iff x=0$. 
\end{definition}

\begin{definition}
\deflabel

An \ac{inner product} on a real vector space is a symmetric, positive definite bilinear form. 
\end{definition}

With inner products, you can do geometry, define lengths, angles, etc. Over the next few lectures, we are going to classify all the possible inner products. We'll find that they're not all that different from the normal dot product. In fact, we'll find that they're all isomorphic to the dot product under suitable coordinates.

\begin{example}
\exlabel 

Let's attempt to characterize the qualities of different binary forms
\[\lgen{\vtwo{x_1}{x_2}, \vtwo{y_1}{y_2}}\]
\end{example}

\begin{figure}[h]
\centering
\begin{tabular}{c|c|c|c|c}
    $(x,y)\mapsto$ ? & bilinear & symmetric & positive semidefinite & positive definite \\
\hline
    $x_1+y_1$ & X & & &  \\
    $x_1y_2$ & Y & X & &  \\
    $x_1y_1-x_2y_2$ & Y & Y & X &  \\
    $x_1y_1$ & Y & Y & Y & X\\
    $x_1y_1 + x_2y_2$ & Y & Y & Y & Y
\end{tabular}
\end{figure}

The first row is not a bilinear form, since it does not satisfy $\gen{\lambda x,y} = \gen{x, \lambda y} = \lambda \gen{x,y}$. The second row is a bilinear form, but is not symmetric in $x$ and $y$. The third row has this symmetry, but is not positive semidefinite, since $\gen{x,x}$ when $x_2 > x_1$ is strictly negative. The third row is positive semidefinite, but not positive definite, since $x_1=0$ is sufficient for $x$ to have length $0$. Finally, the last row is the usual dot product, so it satisfies all conditions for an inner product as we expect.  

Now, let's generalize the Hermitian inner product.

\begin{definition}
\deflabel

Let $V$ be a vector space over $\CC$. We say that $\gen{\cdot ,\cdot}$ is a \ac{Hermitian form} on $V$ if $\gen{x,y}$ is linear in $y$ and $\gen{y,x} = \overline{\gen{x,y}}\quad \forall x,y\in V$.
\end{definition}

Note that this definition implies conjugate linearity in $x$, i.e., $\gen{\lambda x,y} = \overline{\lambda}\gen{x,y}$.

By the way, Hermitian is pronounced ``her--mee--shun".

\begin{definition}
\deflabel

The \ac{adjoint} matrix $A^*$ of any $A\in \CC^{n\times n}$ is given by $A^* = \overline{A}^t$.
\end{definition}

Note that adjoint matrices follow many of the same rules that transpose matrices follow. For example, $(AB)^{*} = (\overline{A}\overline{B})^t = B^*A^*$. 

Therefore, Hermitian forms are almost the same as bilinear forms, but with extra conjugation. In particular, all Hermetian forms also have the matrix representation $\gen{x,y} = x^*Ay$, but with the additional constraint that $A^* = A$, since we need $\gen{x,y} = \overline{\gen{y,x}} = \gen{y,x}^* = x^*A^*{y}$. Like bilinear forms, the change of basis for Hermitian forms maps $A\mapsto B^*AB$. 

Since $\overline{\gen{x,x}} = \gen{x,x}$, we have $\gen{x,x}\in \RR$, so inequalities are well-defined and we can use the same definitions for \ac{positive semidefinite} and \ac{positive definite} as before.

\begin{definition}
\deflabel

A \ac{Hermitian inner product} is a positive definite hermitian form. 
\end{definition}

More on Hermitian inner products later. Now, let's look at some applications of bilinear forms. 

\begin{example}
\exlabel

We can use bilinear forms to study quadratic functions. Consider any second degree polynomial in $x_1, \hdots, x_n$. 
\end{example}

We can represent our function in the following way:

\[\underbrace{x^tAx}_{\text{quadratic terms}} + \underbrace{b^tx}_{\text{linear terms}} + \underbrace{c}_{\text{constants}}, \text{ with }A\in F^{n\times n}, b\in F^n, c\in F.\]

Note that since we have $x^tAx = (x^tAx)^t = x^tA^tx$, we can replace $A$ with $(A+A^t)/2$ and our expression still holds, as long as $2\neq 0$ in our field. Since $(A+A^t)/2$ is symmetric, we may therefore assume that it is always true that $A = A^t$.

For example, we may have
\[3x^2 + 4xy + 5y^2 = \htwo{x}{y}\twotwo{3}{1}{3}{5}\vtwo{x}{y},\]
where $A = \twotwo{3}{1}{3}{5}$. Using $(A+A^t)/2$ instead, we find that the symmetric matrix $\twotwo{3}{2}{2}{5}$ also works. \V

\begin{example}
\exlabel 

Using the same idea, we can also use bilinear forms to represent the second degree taylor polynomial of any function $f: \RR^n\rightarrow \RR$ at $x_0 = \RR^n$. 
\end{example}

In this case, we can let 
\begin{align*}
    A_{ij} = \frac{\partial^2 f}{\partial x_i\partial x_j}(x_0), \\
    b = \nabla f(x_0), \\
    c = f(x_0).
\end{align*}
Since partial derivatives commute, $A$ is symmetric!



