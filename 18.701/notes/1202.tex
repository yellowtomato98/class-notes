\section{December 2, 2022}

\subsection{Linear algebra over a skew field}

Last time, we found a nice characterization for $SU_2$:
\[SU_2 =\left\{\twotwo{\alpha}{\beta}{-\overline{\beta}}{-\overline{\alpha}} : \alpha,\beta \in \CC, \norm{\alpha}^2+\norm{\beta}^2 = 1\right\} \cong \{\alpha\in \HH: \norm{\alpha}=1\}.\]

We called $\HH$ a \ac{skew field} because it satisfies all the properties of a normal field, with the exception of commutative multiplication. Let's attempt to do linear algebra over $\HH$. 

$\HH$ can act on $\HH^n$ by left or right multiplication. Let's choose left scalar multiplication. Consider the map given by $x\mapsto \alpha x = f(x)$ for $x\in \HH$. This is (generally) not a linear transformation. In order for our map to be a linear transformation, we need $f(x+y) = f(x)+f(y)$, which we have. We also need $f(\beta x) = \beta (f(x)) \iff \alpha (\beta x) = \beta (\alpha x)$. But by letting $x=1$ this is only true when $\alpha\beta = \beta\alpha$. Since $\HH$ isn't commutative, this does not necessarily hold. 

On the other hand, let's see what happens when $\HH$ acts on $\HH^n$ by right multiplication. Let $f(x) = x\alpha$. Now, since $\HH$ is associative, $(\beta x)\alpha = \beta (x\alpha)$, so $f(\beta x) = \beta f(x)$, so we have a linear transformation. 

\hrulebar

Why are quaternions important? Philosophically, one-third of mathematics is controlled by quaternions. For instance, consider the classification of compact Lie groups (Prof. Cohn emphasizes the Lie should be pronounced as ``lee''). A lie group is both a group and a manifold. A manifold is a space that looks locally like $\RR^n$. Compact approximately means closed and bounded, which means that every sequence of points has a convergence subsequence. 

\begin{theorem}
\thmlabel

Compact, connected Lie groups are always a quotient by a finite central subgroup of some product of groups isomorphic to
\begin{itemize}
    \item $S^1$
    \item $\spin_n$ $(\spin_n/\{\pm 1\}\cong SO_n)$
    \item $SU_n$
    \item The quaternionic unitary group $U_n(\HH)\subseteq GL_n(\HH)$, defined as the set of matrices which preserves the quaternionic Hermetian form (we will define this later)
    \item $G_2$, $F_4$, $E_6$, $E_7$, $E_8$
\end{itemize}
\end{theorem}

This is imprecise, but the idea is that $\RR, \CC$, and $\HH$ contribute equally towards generating linear groups; therefore, $\HH$ is just as important and useful as the other two, even if it just seems more abstract. 

\subsection{Rotations in $\RR^4$}

We can also view $\HH$ as $\RR^4$, which will ultimately lead us back to $SO_3$ and the reason why we started looking at quaternions in the first place.
So far, we have a natural way to compute the norm of any $\alpha\in \HH$, so just like $\RR$ and $\CC$, we should also be able to construct a quaternion Hermetian form. In particular, let
 \begin{align*}
 \gen{\alpha, \beta} &= \re ({\alpha\overline{\beta}}) \\
     &= \re ({(\alpha_1 + \alpha_2\ihat + \alpha_3\jhat + \alpha_4\khat) (\beta_1 - \beta_2\ihat - \beta_3\jhat - \beta_4\khat)}) \\
     &= \alpha_1\beta_1 + \alpha_2\beta_2 + \hdots, \alpha_4\beta_4.
 \end{align*}

\begin{theorem}
\proplabel

If $\vert\alpha\vert = 1$, then $\alpha, \ihat \alpha, \jhat \alpha, \khat \alpha$ is an orthonormal basis of $\HH$. 
\end{theorem}

\begin{proof}

For $\ihat\alpha$ and $\jhat\alpha$,
\[\gen{\ihat\alpha, \jhat\alpha} = \re (\ihat\alpha \overline{\alpha}(-\jhat)) = \re (\ihat \norm{\alpha}^2(-\jhat)) = \re(-\ihat\jhat) = \re(-\khat) = 0.\]
Similar calculations hold for the other pairs of vectors. 
\end{proof}

The consequence of this is that $x\mapsto x\alpha$ and $x\mapsto \alpha x$ are orthogonal transformations of $\RR^4$ if $\vert\alpha\vert = 1$ (we view $\HH$ as $\RR^4$). The same holds for $x\mapsto \overline{x}\alpha$ and $x\mapsto \alpha\overline{x}$. This gives us the following:

\begin{theorem}
\thmlabel

$\forall \alpha, \beta\in \HH$ with $\vert\alpha\vert = \vert\beta\vert = 1$, $x\mapsto \alpha x\beta$ and $x\mapsto \alpha\overline{x}\beta$ are in $O_4(\RR)$. 
\end{theorem}

This is a direct result of our previous Proposition. We can think of $x\mapsto \alpha x\beta$ as our ``orientation-preserving'' maps, i.e., they are composed of an even number of reflections and have determinant $+1$. We can think of $x\mapsto \alpha\overline{x}\beta$ as our ``orientation-reversing'' maps, i.e., they are composed of an odd number of reflections and have determinant $-1$. 

\begin{theorem}
\thmlabel

And this is all of $O_4(\RR)$. 
\end{theorem}

\begin{proof}
We take for granted that $O_4(\RR)$ is generated by reflections in hyperplanes, which we proved in Problem Set $6$. Now, the key idea is that 
\[x\mapsto -\alpha\overline{x}\alpha\]
is a reflection in the hyperplane perpendicular to $\alpha$. We can verify this: 
\begin{align*}
    \alpha &\mapsto (-\alpha\ov{\alpha}\alpha) =  (-\norm{\alpha}^2\alpha) = -\alpha \\
    \ihat\alpha &\mapsto (-\alpha \ov{\ihat\alpha}\alpha) = (-\alpha\ov{\alpha}(-\ihat)\alpha) = \ihat\alpha,
\end{align*}
and similarly for $\jhat$, $\khat$ (sign preserved). Since $O_4(\RR)$ is generated by reflections, any element is equal to some
\[\left(x\mapsto \prod_{i}(-\alpha_i\overline{x}\alpha_i)\right) = \left(x\mapsto -\alpha_1\left(\prod_{i>1}(-\alpha_i\overline{x}\alpha_i)\right)\alpha_1\right) = \hdots\]
where a chain of unit $\alpha$ grows on each side of $x$ and the orientation of $x$ flips for each new $\alpha$ (this is somewhat abusive notation, we're mixing up composition and actual multiplication). Therefore, every element in $O_4(\RR)$ is $x\mapsto \alpha\ov{x}\beta$ or $x\mapsto \alpha x\beta$ for some unit $\alpha, \beta\in \HH$.
\end{proof}

Note that whenever we end up with a mapping of the form $x\mapsto \alpha x\beta$, this means that we composed an even number of reflections, so these maps make up $SO_4(\RR)$. On the other hand, mappings of the form $x\mapsto \alpha\ov{x}\beta$ composed an odd number of reflections, so these are the elements in $O_4(\RR)$ not in $SO_4(\RR)$.

\subsection{$SU_2$ is a double cover for $SO_3$}

How do we connect this back to $3d$ rotations? Let's look at the imaginary quaternions, i.e., $\RR_i\oplus\RR_j\oplus \RR_k\cong \RR^3$.

A $3d$ rotation of $\RR_i\oplus\RR_j\oplus \RR_k$ is equivalent to a $4d$ rotation of $\HH$ which fixes $1$, i.e., a mapping $x\mapsto \alpha x\beta$ such that $\alpha\cdot 1\cdot \beta = 1\implies \beta = \alpha^{-1}$. $SO_3$ is just conjugation by unit quaternions! Kind of. All this implies is that every rotation can be represented by some unit quaternion, so we have a homomorphism 
\begin{align*}
    \gamma : SU_2\cong \{\alpha\in \HH: \norm{\alpha}=1\}&\rightarrow SO_3 \\
    \alpha &\mapsto (x\mapsto \alpha x\alpha^{-1}).
\end{align*}

This implies $SO_3\cong SU_2/\ker{\gamma}$. Now, $\alpha\in \ker(\gamma)$ if and only if $\alpha x = x\alpha$ for all unit $x\in \HH$. If $\alpha = \alpha_1 + \alpha_2\ihat + \alpha_3\jhat + \alpha_4\khat$, then $x=\ihat$ implies 
\[\alpha_1\ihat + \alpha_2(-1) + \alpha_3(-\khat) + \alpha_4(\jhat) = \alpha_1\ihat + \alpha_2(-1) + \alpha_3(\khat) + \alpha_4(\jhat),\]
so $\alpha_3 = \alpha_4 = 0$. Repeating this calculation for the other basis vectors gives $\ima(\alpha)=0$, so $\alpha=\pm 1$ and $SO_3\cong SU_2/\{\pm 1\}$. 

What this means is that $SO_3$ is \textit{almost} conjugation by unit quaternions, it just can't distinguish between $\pm \alpha$, where $\alpha$ is the element we're conjugating with. For this reason, we call $SU_2$ a \ac{double cover} of $SO_3$, and for most applications this is good enough. Prof. Cohn talks a about a deep connection to electron spin, but I don't know enough about physics to understand. 